{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onlyabhilash/Transformers_with_NLP/blob/main/Linformer/Linformer_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dyUSjoK_36W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "bb799e17-d19d-4347-b422-60f4c0debcf8"
      },
      "source": [
        "!git clone https://github.com/tatp22/linformer-pytorch.git\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'linformer-pytorch'...\n",
            "remote: Enumerating objects: 88, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/88)\u001b[K\rremote: Counting objects:   2% (2/88)\u001b[K\rremote: Counting objects:   3% (3/88)\u001b[K\rremote: Counting objects:   4% (4/88)\u001b[K\rremote: Counting objects:   5% (5/88)\u001b[K\rremote: Counting objects:   6% (6/88)\u001b[K\rremote: Counting objects:   7% (7/88)\u001b[K\rremote: Counting objects:   9% (8/88)\u001b[K\rremote: Counting objects:  10% (9/88)\u001b[K\rremote: Counting objects:  11% (10/88)\u001b[K\rremote: Counting objects:  12% (11/88)\u001b[K\rremote: Counting objects:  13% (12/88)\u001b[K\rremote: Counting objects:  14% (13/88)\u001b[K\rremote: Counting objects:  15% (14/88)\u001b[K\rremote: Counting objects:  17% (15/88)\u001b[K\rremote: Counting objects:  18% (16/88)\u001b[K\rremote: Counting objects:  19% (17/88)\u001b[K\rremote: Counting objects:  20% (18/88)\u001b[K\rremote: Counting objects:  21% (19/88)\u001b[K\rremote: Counting objects:  22% (20/88)\u001b[K\rremote: Counting objects:  23% (21/88)\u001b[K\rremote: Counting objects:  25% (22/88)\u001b[K\rremote: Counting objects:  26% (23/88)\u001b[K\rremote: Counting objects:  27% (24/88)\u001b[K\rremote: Counting objects:  28% (25/88)\u001b[K\rremote: Counting objects:  29% (26/88)\u001b[K\rremote: Counting objects:  30% (27/88)\u001b[K\rremote: Counting objects:  31% (28/88)\u001b[K\rremote: Counting objects:  32% (29/88)\u001b[K\rremote: Counting objects:  34% (30/88)\u001b[K\rremote: Counting objects:  35% (31/88)\u001b[K\rremote: Counting objects:  36% (32/88)\u001b[K\rremote: Counting objects:  37% (33/88)\u001b[K\rremote: Counting objects:  38% (34/88)\u001b[K\rremote: Counting objects:  39% (35/88)\u001b[K\rremote: Counting objects:  40% (36/88)\u001b[K\rremote: Counting objects:  42% (37/88)\u001b[K\rremote: Counting objects:  43% (38/88)\u001b[K\rremote: Counting objects:  44% (39/88)\u001b[K\rremote: Counting objects:  45% (40/88)\u001b[K\rremote: Counting objects:  46% (41/88)\u001b[K\rremote: Counting objects:  47% (42/88)\u001b[K\rremote: Counting objects:  48% (43/88)\u001b[K\rremote: Counting objects:  50% (44/88)\u001b[K\rremote: Counting objects:  51% (45/88)\u001b[K\rremote: Counting objects:  52% (46/88)\u001b[K\rremote: Counting objects:  53% (47/88)\u001b[K\rremote: Counting objects:  54% (48/88)\u001b[K\rremote: Counting objects:  55% (49/88)\u001b[K\rremote: Counting objects:  56% (50/88)\u001b[K\rremote: Counting objects:  57% (51/88)\u001b[K\rremote: Counting objects:  59% (52/88)\u001b[K\rremote: Counting objects:  60% (53/88)\u001b[K\rremote: Counting objects:  61% (54/88)\u001b[K\rremote: Counting objects:  62% (55/88)\u001b[K\rremote: Counting objects:  63% (56/88)\u001b[K\rremote: Counting objects:  64% (57/88)\u001b[K\rremote: Counting objects:  65% (58/88)\u001b[K\rremote: Counting objects:  67% (59/88)\u001b[K\rremote: Counting objects:  68% (60/88)\u001b[K\rremote: Counting objects:  69% (61/88)\u001b[K\rremote: Counting objects:  70% (62/88)\u001b[K\rremote: Counting objects:  71% (63/88)\u001b[K\rremote: Counting objects:  72% (64/88)\u001b[K\rremote: Counting objects:  73% (65/88)\u001b[K\rremote: Counting objects:  75% (66/88)\u001b[K\rremote: Counting objects:  76% (67/88)\u001b[K\rremote: Counting objects:  77% (68/88)\u001b[K\rremote: Counting objects:  78% (69/88)\u001b[K\rremote: Counting objects:  79% (70/88)\u001b[K\rremote: Counting objects:  80% (71/88)\u001b[K\rremote: Counting objects:  81% (72/88)\u001b[K\rremote: Counting objects:  82% (73/88)\u001b[K\rremote: Counting objects:  84% (74/88)\u001b[K\rremote: Counting objects:  85% (75/88)\u001b[K\rremote: Counting objects:  86% (76/88)\u001b[K\rremote: Counting objects:  87% (77/88)\u001b[K\rremote: Counting objects:  88% (78/88)\u001b[K\rremote: Counting objects:  89% (79/88)\u001b[K\rremote: Counting objects:  90% (80/88)\u001b[K\rremote: Counting objects:  92% (81/88)\u001b[K\rremote: Counting objects:  93% (82/88)\u001b[K\rremote: Counting objects:  94% (83/88)\u001b[K\rremote: Counting objects:  95% (84/88)\u001b[K\rremote: Counting objects:  96% (85/88)\u001b[K\rremote: Counting objects:  97% (86/88)\u001b[K\rremote: Counting objects:  98% (87/88)\u001b[K\rremote: Counting objects: 100% (88/88)\u001b[K\rremote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/63)\u001b[K\rremote: Compressing objects:   3% (2/63)\u001b[K\rremote: Compressing objects:   4% (3/63)\u001b[K\rremote: Compressing objects:   6% (4/63)\u001b[K\rremote: Compressing objects:   7% (5/63)\u001b[K\rremote: Compressing objects:   9% (6/63)\u001b[K\rremote: Compressing objects:  11% (7/63)\u001b[K\rremote: Compressing objects:  12% (8/63)\u001b[K\rremote: Compressing objects:  14% (9/63)\u001b[K\rremote: Compressing objects:  15% (10/63)\u001b[K\rremote: Compressing objects:  17% (11/63)\u001b[K\rremote: Compressing objects:  19% (12/63)\u001b[K\rremote: Compressing objects:  20% (13/63)\u001b[K\rremote: Compressing objects:  22% (14/63)\u001b[K\rremote: Compressing objects:  23% (15/63)\u001b[K\rremote: Compressing objects:  25% (16/63)\u001b[K\rremote: Compressing objects:  26% (17/63)\u001b[K\rremote: Compressing objects:  28% (18/63)\u001b[K\rremote: Compressing objects:  30% (19/63)\u001b[K\rremote: Compressing objects:  31% (20/63)\u001b[K\rremote: Compressing objects:  33% (21/63)\u001b[K\rremote: Compressing objects:  34% (22/63)\u001b[K\rremote: Compressing objects:  36% (23/63)\u001b[K\rremote: Compressing objects:  38% (24/63)\u001b[K\rremote: Compressing objects:  39% (25/63)\u001b[K\rremote: Compressing objects:  41% (26/63)\u001b[K\rremote: Compressing objects:  42% (27/63)\u001b[K\rremote: Compressing objects:  44% (28/63)\u001b[K\rremote: Compressing objects:  46% (29/63)\u001b[K\rremote: Compressing objects:  47% (30/63)\u001b[K\rremote: Compressing objects:  49% (31/63)\u001b[K\rremote: Compressing objects:  50% (32/63)\u001b[K\rremote: Compressing objects:  52% (33/63)\u001b[K\rremote: Compressing objects:  53% (34/63)\u001b[K\rremote: Compressing objects:  55% (35/63)\u001b[K\rremote: Compressing objects:  57% (36/63)\u001b[K\rremote: Compressing objects:  58% (37/63)\u001b[K\rremote: Compressing objects:  60% (38/63)\u001b[K\rremote: Compressing objects:  61% (39/63)\u001b[K\rremote: Compressing objects:  63% (40/63)\u001b[K\rremote: Compressing objects:  65% (41/63)\u001b[K\rremote: Compressing objects:  66% (42/63)\u001b[K\rremote: Compressing objects:  68% (43/63)\u001b[K\rremote: Compressing objects:  69% (44/63)\u001b[K\rremote: Compressing objects:  71% (45/63)\u001b[K\rremote: Compressing objects:  73% (46/63)\u001b[K\rremote: Compressing objects:  74% (47/63)\u001b[K\rremote: Compressing objects:  76% (48/63)\u001b[K\rremote: Compressing objects:  77% (49/63)\u001b[K\rremote: Compressing objects:  79% (50/63)\u001b[K\rremote: Compressing objects:  80% (51/63)\u001b[K\rremote: Compressing objects:  82% (52/63)\u001b[K\rremote: Compressing objects:  84% (53/63)\u001b[K\rremote: Compressing objects:  85% (54/63)\u001b[K\rremote: Compressing objects:  87% (55/63)\u001b[K\rremote: Compressing objects:  88% (56/63)\u001b[K\rremote: Compressing objects:  90% (57/63)\u001b[K\rremote: Compressing objects:  92% (58/63)\u001b[K\rremote: Compressing objects:  93% (59/63)\u001b[K\rremote: Compressing objects:  95% (60/63)\u001b[K\rremote: Compressing objects:  96% (61/63)\u001b[K\rremote: Compressing objects:  98% (62/63)\u001b[K\rremote: Compressing objects: 100% (63/63)\u001b[K\rremote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 88 (delta 43), reused 57 (delta 22), pack-reused 0\u001b[K\n",
            "Unpacking objects:   1% (1/88)   \rUnpacking objects:   2% (2/88)   \rUnpacking objects:   3% (3/88)   \rUnpacking objects:   4% (4/88)   \rUnpacking objects:   5% (5/88)   \rUnpacking objects:   6% (6/88)   \rUnpacking objects:   7% (7/88)   \rUnpacking objects:   9% (8/88)   \rUnpacking objects:  10% (9/88)   \rUnpacking objects:  11% (10/88)   \rUnpacking objects:  12% (11/88)   \rUnpacking objects:  13% (12/88)   \rUnpacking objects:  14% (13/88)   \rUnpacking objects:  15% (14/88)   \rUnpacking objects:  17% (15/88)   \rUnpacking objects:  18% (16/88)   \rUnpacking objects:  19% (17/88)   \rUnpacking objects:  20% (18/88)   \rUnpacking objects:  21% (19/88)   \rUnpacking objects:  22% (20/88)   \rUnpacking objects:  23% (21/88)   \rUnpacking objects:  25% (22/88)   \rUnpacking objects:  26% (23/88)   \rUnpacking objects:  27% (24/88)   \rUnpacking objects:  28% (25/88)   \rUnpacking objects:  29% (26/88)   \rUnpacking objects:  30% (27/88)   \rUnpacking objects:  31% (28/88)   \rUnpacking objects:  32% (29/88)   \rUnpacking objects:  34% (30/88)   \rUnpacking objects:  35% (31/88)   \rUnpacking objects:  36% (32/88)   \rUnpacking objects:  37% (33/88)   \rUnpacking objects:  38% (34/88)   \rUnpacking objects:  39% (35/88)   \rUnpacking objects:  40% (36/88)   \rUnpacking objects:  42% (37/88)   \rUnpacking objects:  43% (38/88)   \rUnpacking objects:  44% (39/88)   \rUnpacking objects:  45% (40/88)   \rUnpacking objects:  46% (41/88)   \rUnpacking objects:  47% (42/88)   \rUnpacking objects:  48% (43/88)   \rUnpacking objects:  50% (44/88)   \rUnpacking objects:  51% (45/88)   \rUnpacking objects:  52% (46/88)   \rUnpacking objects:  53% (47/88)   \rUnpacking objects:  54% (48/88)   \rUnpacking objects:  55% (49/88)   \rUnpacking objects:  56% (50/88)   \rUnpacking objects:  57% (51/88)   \rUnpacking objects:  59% (52/88)   \rUnpacking objects:  60% (53/88)   \rUnpacking objects:  61% (54/88)   \rUnpacking objects:  62% (55/88)   \rUnpacking objects:  63% (56/88)   \rUnpacking objects:  64% (57/88)   \rUnpacking objects:  65% (58/88)   \rUnpacking objects:  67% (59/88)   \rUnpacking objects:  68% (60/88)   \rUnpacking objects:  69% (61/88)   \rUnpacking objects:  70% (62/88)   \rUnpacking objects:  71% (63/88)   \rUnpacking objects:  72% (64/88)   \rUnpacking objects:  73% (65/88)   \rUnpacking objects:  75% (66/88)   \rUnpacking objects:  76% (67/88)   \rUnpacking objects:  77% (68/88)   \rUnpacking objects:  78% (69/88)   \rUnpacking objects:  79% (70/88)   \rUnpacking objects:  80% (71/88)   \rUnpacking objects:  81% (72/88)   \rUnpacking objects:  82% (73/88)   \rUnpacking objects:  84% (74/88)   \rUnpacking objects:  85% (75/88)   \rUnpacking objects:  86% (76/88)   \rUnpacking objects:  87% (77/88)   \rUnpacking objects:  88% (78/88)   \rUnpacking objects:  89% (79/88)   \rUnpacking objects:  90% (80/88)   \rUnpacking objects:  92% (81/88)   \rUnpacking objects:  93% (82/88)   \rUnpacking objects:  94% (83/88)   \rUnpacking objects:  95% (84/88)   \rUnpacking objects:  96% (85/88)   \rUnpacking objects:  97% (86/88)   \rUnpacking objects:  98% (87/88)   \rUnpacking objects: 100% (88/88)   \rUnpacking objects: 100% (88/88), done.\n",
            "linformer-pytorch  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO71NrtcB57C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "660efe0b-4151-41fe-c4da-cdf524f2e3d5"
      },
      "source": [
        "%cd linformer-pytorch/\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/linformer-pytorch\n",
            "Sun Jun 14 13:36:34 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8HyRUUvB_59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "4fe87ab8-ef81-4602-c958-d8697b9d6d40"
      },
      "source": [
        "from linformer_pytorch import Linformer\n",
        "import torch\n",
        "\n",
        "model = Linformer(\n",
        "        input_size=1234567, # Dimension 1 of the input\n",
        "        channels=128, # Dimension 2 of the input\n",
        "        dim_d=128, # The inner dimension of the attention heads\n",
        "        dim_k=128, # The second dimension of the P_bar matrix from the paper\n",
        "        dim_ff=128, # Dimension in the feed forward network\n",
        "        dropout_ff=0.15, # Dropout for feed forward network\n",
        "        nhead=6, # Number of attention heads\n",
        "        depth=2, # How many times to run the model\n",
        "        dropout=0.1, # How much dropout to apply to P_bar after softmax\n",
        "        activation=\"gelu\", # What activation to use. Currently, only gelu and relu supported, and only on ff network.\n",
        "        checkpoint_level=\"C2\", # What checkpoint level to use. For more information, see below.\n",
        "        ).cuda()\n",
        "x = torch.randn(1, 1234567, 128).cuda()\n",
        "y = model(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.2311,  0.3724,  0.1700,  ...,  0.6517,  0.5588,  0.3824],\n",
            "         [ 0.1300,  1.9948,  0.5017,  ..., -1.9228,  0.0222,  0.6909],\n",
            "         [-0.9513,  0.7749, -1.0926,  ..., -1.1804,  1.3924, -0.8963],\n",
            "         ...,\n",
            "         [ 1.9377,  0.3684, -1.1223,  ...,  1.1780,  1.6344, -1.4016],\n",
            "         [-1.7335, -0.0192, -1.4493,  ..., -0.1998, -0.5671,  0.1379],\n",
            "         [ 0.6715, -0.6191, -0.4074,  ...,  0.9480,  0.4403, -1.1971]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}